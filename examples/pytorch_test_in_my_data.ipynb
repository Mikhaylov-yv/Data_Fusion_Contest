{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Подготовить-процессы-обработки-данных\" data-toc-modified-id=\"Подготовить-процессы-обработки-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовить процессы обработки данных</a></span></li><li><span><a href=\"#Создать-пакет-данных-и-итератор\" data-toc-modified-id=\"Создать-пакет-данных-и-итератор-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Создать пакет данных и итератор</a></span></li><li><span><a href=\"#Определите-модель\" data-toc-modified-id=\"Определите-модель-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Определите модель</a></span></li><li><span><a href=\"#Инициировать-экземпляр\" data-toc-modified-id=\"Инициировать-экземпляр-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Инициировать экземпляр</a></span></li><li><span><a href=\"#Определите-функции-для-обучения-модели-и-оценки-результатов.\" data-toc-modified-id=\"Определите-функции-для-обучения-модели-и-оценки-результатов.-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Определите функции для обучения модели и оценки результатов.</a></span></li><li><span><a href=\"#Разделите-набор-данных-и-запустите-модель\" data-toc-modified-id=\"Разделите-набор-данных-и-запустите-модель-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Разделите набор данных и запустите модель</a></span></li><li><span><a href=\"#Оцените-модель-с-помощью-тестового-набора-данных\" data-toc-modified-id=\"Оцените-модель-с-помощью-тестового-набора-данных-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Оцените модель с помощью тестового набора данных</a></span></li><li><span><a href=\"#Тест-на-случайной-новости\" data-toc-modified-id=\"Тест-на-случайной-новости-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Тест на случайной новости</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Классификация текста с помощью библиотеки torchtext\n",
    "==================================\n",
    "\n",
    "В этом руководстве мы покажем, как использовать библиотеку torchtext для создания набора данных для анализа классификации текста. Пользователи будут иметь возможность\n",
    "\n",
    "\n",
    "    - Доступ к необработанным данным в качестве итератора\n",
    "    - Создание конвейера обработки данных для преобразования необработанных текстовых строк в torch.Tensor, который можно использовать для обучения модели.\n",
    "    - Перемешивайте и повторяйте данные с помощью `torch.utils.data.DataLoader\n",
    "    \n",
    "<https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Загрузка данных\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список категорий в тестовых данных\n",
    "# pd.read_pickle('../data/input/test_data_4300_rows.pkl')['category_id'].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43146</th>\n",
       "      <td>78</td>\n",
       "      <td>Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_id                                          item_name\n",
       "43146           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/input/test_data_all_rows.pkl')[['category_id', 'item_name']]\n",
    "df[df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(path, cat_dict = {}):\n",
    "    df = pd.read_pickle(path)[[\n",
    "                            'category_id', 'item_name']]\n",
    "#     df = df[~df.category_id.isin([0, 133, 3, 177, 43, 18, 120, 45, 2, 49, 66, 30, 118, 7])]\n",
    "    if cat_dict == {}:\n",
    "        cat_num = 0\n",
    "        for category_id in  df.category_id.drop_duplicates():\n",
    "            cat_dict[category_id] = cat_num\n",
    "            df.loc[df.category_id == category_id, 'category_id_new'] = cat_num\n",
    "            cat_num += 1\n",
    "        return df, cat_dict\n",
    "    else:\n",
    "        df['category_id_new'] = df.category_id.map(cat_dict)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{78: 0, 71: 1, 70: 2, 84: 3, 69: 4, 68: 5, 40: 6, 203: 7, 79: 8, 7: 9, 117: 10, 80: 11, 83: 12, 53: 13, 73: 14, 81: 15, 0: 16, 12: 17, 85: 18, 77: 19, 145: 20, 2: 21, 204: 22, 139: 23, 38: 24, 74: 25, 130: 26, 75: 27, 49: 28, 45: 29, 133: 30, 76: 31, 82: 32, 19: 33, 43: 34, 51: 35, 61: 36, 177: 37, 118: 38, 92: 39, 36: 40, 30: 41, 167: 42, 66: 43, 52: 44, 107: 45, 37: 46, 3: 47, 72: 48, 62: 49, 50: 50, 120: 51, 42: 52, 150: 53, 57: 54, 6: 55, 140: 56, 101: 57, 163: 58, 20: 59, 103: 60, 4: 61, 31: 62, 67: 63, 27: 64, 29: 65, 114: 66, 102: 67, 115: 68, 26: 69, 35: 70, 39: 71, 13: 72, 9: 73, 128: 74, 60: 75, 41: 76, 138: 77, 11: 78, 100: 79, 24: 80, 96: 81, 109: 82, 106: 83, 56: 84, 143: 85, 105: 86, 90: 87, 1: 88, 108: 89, 164: 90, 55: 91, 111: 92, 58: 93, 54: 94, 97: 95, 46: 96, 121: 97}\n",
      "(48267, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0, 'Молоко 3,2%,шт'],\n",
       "       [1.0, 'Компот из изюма, 114 ккал'],\n",
       "       [1.0, 'Макаронные изделия отварные (масло сливочное), 240 ккал'],\n",
       "       ...,\n",
       "       [16.0, 'Пиво светлое \"Халзан\" 4,5 % об, пл/б. 1,5 л(шт)'],\n",
       "       [52.0, 'Экспресс педикюр'],\n",
       "       [3.0, 'Конфеты Харитоша 1кг мол. ваф Яшкино']], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, cat_dict = open_data('../data/input/test_data_all_rows.pkl')\n",
    "train_data = train_df[['category_id_new', 'item_name']].to_numpy()\n",
    "print(cat_dict)\n",
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл'],\n",
       "       [11, 'Мандарины с листиком 1кг'],\n",
       "       [3, 'Хлеб/бул изделие 200г отруби  ХБЗ №2'],\n",
       "       ...,\n",
       "       [7, 'Пакет'],\n",
       "       [19, '230Г СОУС КАЛЬВЕ С ЛЕСНЫМИ ГРИ'],\n",
       "       [7, 'ЗЕЛПМ-КА32Х62Х17']], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = open_data('../data/input/test_data_6350_rows.pkl',cat_dict = cat_dict)\n",
    "test_data = test_df[['category_id_new', 'item_name']].to_numpy()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          category_id                                          item_name  \\\n",
      "27702571           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...   \n",
      "\n",
      "          category_id_new  \n",
      "27702571                0   \n",
      "        category_id                                          item_name  \\\n",
      "43146           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...   \n",
      "\n",
      "       category_id_new  \n",
      "43146              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Test load Data\n",
    "item_name_train = test_df.loc[test_df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']\n",
    "item_name_test = train_df.loc[\n",
    "            train_df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']\n",
    "print(item_name_train, '\\n', item_name_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовить процессы обработки данных\n",
    "---------------------------------\n",
    "\n",
    "Мы пересмотрели самые основные компоненты библиотеки torchtext, включая словарь, векторы слов, токенизатор. Это основные строительные блоки обработки данных для необработанной текстовой строки.\n",
    "\n",
    "Вот пример типичной обработки данных НЛП с помощью токенизатора и словаря. Первым шагом является создание словаря с помощью необработанного набора обучающих данных. Пользователи могут иметь собственный словарь, задав аргументы в конструкторе класса Vocab. Например, минимальная частота ``min_freq`` для включения токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "# train_iter = AG_NEWS(split='train')\n",
    "counter = Counter()\n",
    "for label, line in train_data:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок словаря преобразует список токенов в целые числа.\n",
    "\n",
    "::\n",
    "\n",
    "    [vocab[token] for token in ['here', 'is', 'an', 'example']]\n",
    "    >>> [476, 22, 31, 5298]\n",
    "\n",
    "Подготовьте конвейер обработки текста с токенизатором и словарем. Конвейеры текста и меток будут использоваться для обработки строк необработанных данных из итераторов набора данных.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текстовый конвейер преобразует текстовую строку в список целых чисел на основе таблицы поиска, определенной в словаре. Конвейер меток преобразует метку в целые числа. Например,\n",
    "\n",
    "::\n",
    "\n",
    "    text_pipeline('here is the an example')\n",
    "    >>> [475, 21, 2, 30, 5286]\n",
    "    label_pipeline('10')\n",
    "    >>> 9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать пакет данных и итератор\n",
    "--------------------------------\n",
    "\n",
    "`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n",
    "рекомендуется для пользователей PyTorch (учебник `here <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>`__).\n",
    "\n",
    "Он работает с набором данных в стиле карты, который реализует протоколы ``getitem()`` и ``len()`` и представляет карту от индексов/ключей до образцов данных. Он также работает с повторяющимися наборами данных с аргументом случайного выбора ``False``.\n",
    "\n",
    "\n",
    "Перед отправкой в модель функция ``collate_fn`` работает с пакетом образцов, сгенерированных из ``DataLoader``. Входом для ``collate_fn`` является пакет данных с размером пакета в ``DataLoader``, и ``collate_fn`` обрабатывает их в соответствии с конвейерами обработки данных, объявленными ранее. Обратите внимание на это и убедитесь, что ``collate_fn`` объявлен как def верхнего уровня. Это гарантирует, что функция доступна каждому исполнителю.\n",
    "\n",
    "В этом примере текстовые записи в исходном вводе пакета данных упаковываются в список и объединяются в один тензор для ввода ``nn.EmbeddingBag``. Смещение - это тензор разделителей, представляющий начальный индекс отдельной последовательности в текстовом тензоре. Метка - это тензор, сохраняющий метки отдельных текстовых записей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)    \n",
    "\n",
    "dataloader = DataLoader(train_data, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите модель\n",
    "----------------\n",
    "\n",
    "Модель состоит из `nn.EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>`__ слой плюс линейный слой для целей классификации. ``nn.EmbeddingBag`` с режимом по умолчанию «mean» вычисляет среднее значение «мешка» вложений. Хотя текстовые записи здесь имеют разную длину, модуль nn.EmbeddingBag здесь не требует заполнения, поскольку длина текста сохраняется в смещениях.\n",
    "\n",
    "Кроме того, поскольку ``nn.EmbeddingBag`` накапливает среднее значение по\n",
    "вложения на лету, ``nn.EmbeddingBag`` может улучшить\n",
    "производительность и эффективность памяти для обработки последовательности тензоров.\n",
    "\n",
    "![](../_static/img/text_sentiment_ngrams_model.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициировать экземпляр\n",
    "--------------------\n",
    "\n",
    "Набор данных ``AG_NEWS`` имеет четыре метки, поэтому количество классов равно четырем.\n",
    "\n",
    "::\n",
    "\n",
    "   1 : World мир\n",
    "   2 : Sports спорт\n",
    "   3 : Business Бизнес\n",
    "   4 : Sci/Tec Наука/Техника\n",
    "\n",
    "Мы строим модель с размером встраивания 64. Размер словаря равен длине экземпляра словаря. Количество классов равно количеству этикеток,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(cat_dict)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите функции для обучения модели и оценки результатов.\n",
    "---------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "#         print(sorted(label))\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите набор данных и запустите модель\n",
    "-----------------------------------\n",
    "\n",
    "Поскольку исходный ``AG_NEWS`` не имеет действительного набора данных, мы разделяем обучение\n",
    "набор данных в обучающие/действительные наборы с коэффициентом разделения 0,95 (train) и\n",
    "0,05 (valid). Здесь мы используем\n",
    "`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n",
    "в базовой библиотеке PyTorch.\n",
    "\n",
    "`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
    "критерий объединяет в одном классе ``nn.LogSoftmax()`` и ``nn.NLLLoss()``.\n",
    "Это полезно при обучении задаче классификации с помощью классов C.\n",
    "`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\n",
    "в качестве оптимизатора реализует метод стохастического градиентного спуска. Начальный\n",
    "скорость обучения установлена на 5.0.\n",
    "`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n",
    "здесь используется для регулировки скорости обучения по эпохам.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 2715 batches | accuracy    0.884\n",
      "| epoch   1 |  1000/ 2715 batches | accuracy    0.879\n",
      "| epoch   1 |  1500/ 2715 batches | accuracy    0.880\n",
      "| epoch   1 |  2000/ 2715 batches | accuracy    0.881\n",
      "| epoch   1 |  2500/ 2715 batches | accuracy    0.886\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  5.96s | valid accuracy    0.876 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 2715 batches | accuracy    0.912\n",
      "| epoch   2 |  1000/ 2715 batches | accuracy    0.911\n",
      "| epoch   2 |  1500/ 2715 batches | accuracy    0.908\n",
      "| epoch   2 |  2000/ 2715 batches | accuracy    0.905\n",
      "| epoch   2 |  2500/ 2715 batches | accuracy    0.907\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  5.80s | valid accuracy    0.874 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 2715 batches | accuracy    0.944\n",
      "| epoch   3 |  1000/ 2715 batches | accuracy    0.939\n",
      "| epoch   3 |  1500/ 2715 batches | accuracy    0.941\n",
      "| epoch   3 |  2000/ 2715 batches | accuracy    0.944\n",
      "| epoch   3 |  2500/ 2715 batches | accuracy    0.937\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.11s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 2715 batches | accuracy    0.949\n",
      "| epoch   4 |  1000/ 2715 batches | accuracy    0.943\n",
      "| epoch   4 |  1500/ 2715 batches | accuracy    0.945\n",
      "| epoch   4 |  2000/ 2715 batches | accuracy    0.942\n",
      "| epoch   4 |  2500/ 2715 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  5.70s | valid accuracy    0.880 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 2715 batches | accuracy    0.941\n",
      "| epoch   5 |  1000/ 2715 batches | accuracy    0.946\n",
      "| epoch   5 |  1500/ 2715 batches | accuracy    0.951\n",
      "| epoch   5 |  2000/ 2715 batches | accuracy    0.953\n",
      "| epoch   5 |  2500/ 2715 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  5.43s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 2715 batches | accuracy    0.951\n",
      "| epoch   6 |  1000/ 2715 batches | accuracy    0.951\n",
      "| epoch   6 |  1500/ 2715 batches | accuracy    0.952\n",
      "| epoch   6 |  2000/ 2715 batches | accuracy    0.952\n",
      "| epoch   6 |  2500/ 2715 batches | accuracy    0.953\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  5.77s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 2715 batches | accuracy    0.952\n",
      "| epoch   7 |  1000/ 2715 batches | accuracy    0.950\n",
      "| epoch   7 |  1500/ 2715 batches | accuracy    0.951\n",
      "| epoch   7 |  2000/ 2715 batches | accuracy    0.949\n",
      "| epoch   7 |  2500/ 2715 batches | accuracy    0.953\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  6.07s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 2715 batches | accuracy    0.952\n",
      "| epoch   8 |  1000/ 2715 batches | accuracy    0.956\n",
      "| epoch   8 |  1500/ 2715 batches | accuracy    0.949\n",
      "| epoch   8 |  2000/ 2715 batches | accuracy    0.949\n",
      "| epoch   8 |  2500/ 2715 batches | accuracy    0.954\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  5.82s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 2715 batches | accuracy    0.949\n",
      "| epoch   9 |  1000/ 2715 batches | accuracy    0.950\n",
      "| epoch   9 |  1500/ 2715 batches | accuracy    0.956\n",
      "| epoch   9 |  2000/ 2715 batches | accuracy    0.954\n",
      "| epoch   9 |  2500/ 2715 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  5.84s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 2715 batches | accuracy    0.955\n",
      "| epoch  10 |  1000/ 2715 batches | accuracy    0.951\n",
      "| epoch  10 |  1500/ 2715 batches | accuracy    0.952\n",
      "| epoch  10 |  2000/ 2715 batches | accuracy    0.953\n",
      "| epoch  10 |  2500/ 2715 batches | accuracy    0.948\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  6.07s | valid accuracy    0.879 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # скорость обучения\n",
    "BATCH_SIZE = 16 # batch size for training\n",
    "  \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "# train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = list(train_data)\n",
    "test_dataset = list(test_data)\n",
    "num_train = int(len(train_dataset) * 0.9)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "# print(train_dataset)\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск модели на GPU со следующей распечаткой:\n",
    "\n",
    "::\n",
    "\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   1 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   2 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   3 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   4 | time:  0.03s | valid accuracy    0.650 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   5 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   6 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   7 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   8 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   9 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch  10 | time:  0.02s | valid accuracy    0.750 \n",
    "    -----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените модель с помощью тестового набора данных\n",
    "------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка результатов тестового набора данных…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка результатов тестового набора данных.\n",
      "точность теста    0.966\n"
     ]
    }
   ],
   "source": [
    "print('Проверка результатов тестового набора данных.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('точность теста {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::\n",
    "\n",
    "    Проверка результатов тестового набора данных.\n",
    "    точность теста    0.950\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест на случайной новости\n",
    "---------------------\n",
    "\n",
    "Используйте лучшую на данный момент модель и проверьте новости гольфа.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это 78 категория\n",
      "Примеры:\n",
      " ['Молоко 3,2%,шт' 'Молоко пастерилиз. т/рекс 2,5 %  1 л. 1/8 БМК'\n",
      " 'Сметана  Кубанский  Молочник  20%  180гр шт' 'СМЕТАНА 20% 300Г'\n",
      " 'Молоко Мудрая хозяйка 2,5% пленка 0,8 л БЗМЖ'\n",
      " '45Г ГЛ/СЫРКИ РОСТАГРО 20% ВН БЗМЖ' 'Пакет'\n",
      " 'Биойогурт \"Козимель\" натуральный,шт'\n",
      " 'Продукт кисломолочный Тема Биолакт 3,2% ТБА 208г'\n",
      " 'Йогурт питьевой Асеньевская фе' 'Сыр Российский 1кг 50% Россия БЗМЖ'\n",
      " 'Сметана 10г, 16 ккал' ' К.Ц.Яйца куриные стол.С2 10шт' 'ЯЙЦО ЭКСТРА С0'\n",
      " 'ЯЙЦО КУРИНОЕ С1 ВАРА' 'Йогурт фруктовый \"Вишня\" 2,5%,шт'\n",
      " 'Молоко Отборн Грин Агро 3,3-4,3% 1л пэт ГМЗ Артем'\n",
      " 'Молоко ФП пастериз т/топ 2,5 % 1,0л 1/6 Хладокомбинат'\n",
      " 'МАСЛО 82,5% ЭКОМ.' 'Яйцо кур С2 10шт пл/бл Племптицезавод'\n",
      " 'Мильфей с клубн.тартаром'\n",
      " 'БЗМЖ Сыр Сметанковый 45 - 50% 250г кусок Продукты из Елани'\n",
      " 'Сметана 20%,шт' 'ЯЙЦО СТОЛОВОЕ 1КАТ. ПТИЦЕФАБРИКА ПИОНЕРСКОЕ 10ШТ'\n",
      " 'Сыр с аром топл мол Черный принц 50% Беларусь'\n",
      " 'Коктейль детский молочный c шоколадом 2,5%,шт' 'МОЛОКО ПМЖЛ 2.5% 900Г'\n",
      " 'Мусс творожный с вишней,шт' 'Сметана 20'\n",
      " 'Яйцо кур С-1 10шт Все вкусное на стол Россия, шт'\n",
      " 'Сыр Мраморный 45% Беларусь' 'Сметана 100г, 159 ккал'\n",
      " 'Масло сливочн ДЕРЕВНЯ СЧАСТЛИВ' 'МОЛОКО ПАСТЕР 2,5%'\n",
      " 'Сыр Российский Село Зеленое 50% фас. 250 г БЗМЖ'\n",
      " 'Творог обезжиренный со сметаной,шт'\n",
      " 'Молоко коровье питьевое пастериз. 2,5% 1000гр Пюр-Пак'\n",
      " 'Кокт Молоч Речка Шоколад 2% БЗМЖ 0,2 МЛ' 'СЫРОК С ВАНИЛЬЮ'\n",
      " 'СЫРОК СУФЛ СОВ ТРАДИ'\n",
      " 'Йогурт десертный ФП земляника 2,5% 180г стакан 1/6'\n",
      " 'Сыр творожный \"Cremette\" 65%  800гр' 'М-З МОСК ПРОВ С ДОЗ'\n",
      " 'МОЛОКО 1Л УЛЬТРАПАСТ' 'Продукт кисломолочный Закваска 1,5% (буфет)'\n",
      " 'Творог 5% 280г шайба Серышевский'\n",
      " 'Кисл/мол продукт БиоМакс 450г 1,0% кефирный пл/б ВБД БЗМЖ'\n",
      " 'ЙогуртНежныйПерсикБЗМЖ5% 110г ван' 'СЫР МААСДАМ 45%'\n",
      " 'Молоко 0,95л 3,2% пл/б МолКом БЗМЖ']\n"
     ]
    }
   ],
   "source": [
    "cat_dict_inverted = dict(map(reversed, cat_dict.items()))\n",
    "\n",
    "def predict(text, text_pipeline = text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "ex_text_str = \"Сыр ПОШЕХОНСКИЙ 45% вес\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "predict_cat = predict(ex_text_str, text_pipeline)\n",
    "print(\"Это %s категория\" %cat_dict_inverted[predict_cat])\n",
    "exsempl_df = pd.DataFrame(train_data)\n",
    "print('Примеры:\\n', exsempl_df[exsempl_df[0] == predict_cat][1][:50].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32644219</th>\n",
       "      <td>84</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27416567</th>\n",
       "      <td>203</td>\n",
       "      <td>ЗЕЛПМ-КА32Х62Х17</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398547</th>\n",
       "      <td>71</td>\n",
       "      <td>Макароны 200 гр.</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31102586</th>\n",
       "      <td>71</td>\n",
       "      <td>Компот 0,2л.</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33164615</th>\n",
       "      <td>74</td>\n",
       "      <td>Окорочка куриные гриль, вес</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16527974</th>\n",
       "      <td>78</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43633645</th>\n",
       "      <td>73</td>\n",
       "      <td>Печень говяжья п/ф</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35226044</th>\n",
       "      <td>77</td>\n",
       "      <td>Майонез Домашний 67% 420мл Лу-ка Россия, шт</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15224849</th>\n",
       "      <td>203</td>\n",
       "      <td>ЗЕЛПМ-КА32Х62Х17</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22913090</th>\n",
       "      <td>203</td>\n",
       "      <td>ЗЕЛПМ-КА32Х62Х17</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          category_id                                    item_name  Pred\n",
       "32644219           84                                        Пакет   203\n",
       "27416567          203                             ЗЕЛПМ-КА32Х62Х17   138\n",
       "9398547            71                             Макароны 200 гр.    76\n",
       "31102586           71                                 Компот 0,2л.    83\n",
       "33164615           74                  Окорочка куриные гриль, вес    79\n",
       "...               ...                                          ...   ...\n",
       "16527974           78                                        Пакет   203\n",
       "43633645           73                           Печень говяжья п/ф    79\n",
       "35226044           77  Майонез Домашний 67% 420мл Лу-ка Россия, шт    78\n",
       "15224849          203                             ЗЕЛПМ-КА32Х62Х17   138\n",
       "22913090          203                             ЗЕЛПМ-КА32Х62Х17   138\n",
       "\n",
       "[214 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = pd.DataFrame({'item_name' : ['Лук', 'Хрен', 'Суп семи залуп', 'АИ95']})\n",
    "df_test = pd.read_pickle('../data/input/test_data_6350_rows.pkl')[['category_id', 'item_name']]\n",
    "df_test['Pred'] = df_test.item_name.apply(predict).map(dict(map(reversed, cat_dict.items())))\n",
    "df_test[df_test.category_id != df_test.Pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::\n",
    "\n",
    "       This is a Sports news\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

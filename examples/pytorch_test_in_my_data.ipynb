{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Подготовить-процессы-обработки-данных\" data-toc-modified-id=\"Подготовить-процессы-обработки-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовить процессы обработки данных</a></span></li><li><span><a href=\"#Создать-пакет-данных-и-итератор\" data-toc-modified-id=\"Создать-пакет-данных-и-итератор-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Создать пакет данных и итератор</a></span></li><li><span><a href=\"#Определите-модель\" data-toc-modified-id=\"Определите-модель-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Определите модель</a></span></li><li><span><a href=\"#Инициировать-экземпляр\" data-toc-modified-id=\"Инициировать-экземпляр-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Инициировать экземпляр</a></span></li><li><span><a href=\"#Определите-функции-для-обучения-модели-и-оценки-результатов.\" data-toc-modified-id=\"Определите-функции-для-обучения-модели-и-оценки-результатов.-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Определите функции для обучения модели и оценки результатов.</a></span></li><li><span><a href=\"#Разделите-набор-данных-и-запустите-модель\" data-toc-modified-id=\"Разделите-набор-данных-и-запустите-модель-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Разделите набор данных и запустите модель</a></span></li><li><span><a href=\"#Оцените-модель-с-помощью-тестового-набора-данных\" data-toc-modified-id=\"Оцените-модель-с-помощью-тестового-набора-данных-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Оцените модель с помощью тестового набора данных</a></span></li><li><span><a href=\"#Тест-на-случайной-новости\" data-toc-modified-id=\"Тест-на-случайной-новости-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Тест на случайной новости</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Классификация текста с помощью библиотеки torchtext\n",
    "==================================\n",
    "\n",
    "В этом руководстве мы покажем, как использовать библиотеку torchtext для создания набора данных для анализа классификации текста. Пользователи будут иметь возможность\n",
    "\n",
    "\n",
    "    - Доступ к необработанным данным в качестве итератора\n",
    "    - Создание конвейера обработки данных для преобразования необработанных текстовых строк в torch.Tensor, который можно использовать для обучения модели.\n",
    "    - Перемешивайте и повторяйте данные с помощью `torch.utils.data.DataLoader\n",
    "    \n",
    "<https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Загрузка данных\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список категорий в тестовых данных\n",
    "# pd.read_pickle('../data/input/test_data_4300_rows.pkl')['category_id'].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43146</th>\n",
       "      <td>78</td>\n",
       "      <td>Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_id                                          item_name\n",
       "43146           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/input/test_data_all_rows.pkl')[['category_id', 'item_name']]\n",
    "df[df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(path, cat_dict = {}):\n",
    "    df = pd.read_pickle(path)[[\n",
    "                            'category_id', 'item_name']]\n",
    "#     df = df[~df.category_id.isin([0, 133, 3, 177, 43, 18, 120, 45, 2, 49, 66, 30, 118, 7])]\n",
    "    if cat_dict == {}:\n",
    "        cat_num = 0\n",
    "        for category_id in  df.category_id.drop_duplicates():\n",
    "            cat_dict[category_id] = cat_num\n",
    "            df.loc[df.category_id == category_id, 'category_id_new'] = cat_num\n",
    "            cat_num += 1\n",
    "        return df, cat_dict\n",
    "    else:\n",
    "        df['category_id_new'] = df.category_id.map(cat_dict)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{78: 0, 71: 1, 70: 2, 84: 3, 69: 4, 68: 5, 40: 6, 203: 7, 79: 8, 7: 9, 117: 10, 80: 11, 83: 12, 53: 13, 73: 14, 81: 15, 0: 16, 12: 17, 85: 18, 77: 19, 145: 20, 2: 21, 204: 22, 139: 23, 38: 24, 74: 25, 130: 26, 75: 27, 49: 28, 45: 29, 133: 30, 76: 31, 82: 32, 19: 33, 43: 34, 51: 35, 61: 36, 177: 37, 118: 38, 92: 39, 36: 40, 30: 41, 167: 42, 66: 43, 52: 44, 107: 45, 37: 46, 3: 47, 72: 48, 62: 49, 50: 50, 120: 51, 42: 52, 150: 53, 57: 54, 6: 55, 140: 56, 101: 57, 163: 58, 20: 59, 103: 60, 4: 61, 31: 62, 67: 63, 27: 64, 29: 65, 114: 66, 102: 67, 115: 68, 26: 69, 35: 70, 39: 71, 13: 72, 9: 73, 128: 74, 60: 75, 41: 76, 138: 77, 11: 78, 100: 79, 24: 80, 96: 81, 109: 82, 106: 83, 56: 84, 143: 85, 105: 86, 90: 87, 1: 88, 108: 89, 164: 90, 55: 91, 111: 92, 58: 93, 54: 94, 97: 95, 46: 96, 121: 97}\n",
      "(48267, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0, 'Молоко 3,2%,шт'],\n",
       "       [1.0, 'Компот из изюма, 114 ккал'],\n",
       "       [1.0, 'Макаронные изделия отварные (масло сливочное), 240 ккал'],\n",
       "       ...,\n",
       "       [16.0, 'Пиво светлое \"Халзан\" 4,5 % об, пл/б. 1,5 л(шт)'],\n",
       "       [52.0, 'Экспресс педикюр'],\n",
       "       [3.0, 'Конфеты Харитоша 1кг мол. ваф Яшкино']], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, cat_dict = open_data('../data/input/test_data_all_rows.pkl')\n",
    "train_data = train_df[['category_id_new', 'item_name']].to_numpy()\n",
    "print(cat_dict)\n",
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл'],\n",
       "       [11, 'Мандарины с листиком 1кг'],\n",
       "       [3, 'Хлеб/бул изделие 200г отруби  ХБЗ №2'],\n",
       "       ...,\n",
       "       [7, 'Пакет'],\n",
       "       [19, '230Г СОУС КАЛЬВЕ С ЛЕСНЫМИ ГРИ'],\n",
       "       [7, 'ЗЕЛПМ-КА32Х62Х17']], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = open_data('../data/input/test_data_6350_rows.pkl',cat_dict = cat_dict)\n",
    "test_data = test_df[['category_id_new', 'item_name']].to_numpy()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          category_id                                          item_name  \\\n",
      "27702571           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...   \n",
      "\n",
      "          category_id_new  \n",
      "27702571                0   \n",
      "        category_id                                          item_name  \\\n",
      "43146           78  Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 9...   \n",
      "\n",
      "       category_id_new  \n",
      "43146              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Test load Data\n",
    "item_name_train = test_df.loc[test_df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']\n",
    "item_name_test = train_df.loc[\n",
    "            train_df.item_name == 'Молоко ДЕРЕВЕНСКОЕ МОЛОЧКО пастер 2.5% п/пак 900мл']\n",
    "print(item_name_train, '\\n', item_name_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовить процессы обработки данных\n",
    "---------------------------------\n",
    "\n",
    "Мы пересмотрели самые основные компоненты библиотеки torchtext, включая словарь, векторы слов, токенизатор. Это основные строительные блоки обработки данных для необработанной текстовой строки.\n",
    "\n",
    "Вот пример типичной обработки данных НЛП с помощью токенизатора и словаря. Первым шагом является создание словаря с помощью необработанного набора обучающих данных. Пользователи могут иметь собственный словарь, задав аргументы в конструкторе класса Vocab. Например, минимальная частота ``min_freq`` для включения токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for label, line in train_data:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок словаря преобразует список токенов в целые числа.\n",
    "\n",
    "::\n",
    "\n",
    "    [vocab[token] for token in ['here', 'is', 'an', 'example']]\n",
    "    >>> [476, 22, 31, 5298]\n",
    "\n",
    "Подготовьте конвейер обработки текста с токенизатором и словарем. Конвейеры текста и меток будут использоваться для обработки строк необработанных данных из итераторов набора данных.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текстовый конвейер преобразует текстовую строку в список целых чисел на основе таблицы поиска, определенной в словаре. Конвейер меток преобразует метку в целые числа. Например,\n",
    "\n",
    "::\n",
    "\n",
    "    text_pipeline('here is the an example')\n",
    "    >>> [475, 21, 2, 30, 5286]\n",
    "    label_pipeline('10')\n",
    "    >>> 9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать пакет данных и итератор\n",
    "--------------------------------\n",
    "\n",
    "`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n",
    "рекомендуется для пользователей PyTorch (учебник `here <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>`__).\n",
    "\n",
    "Он работает с набором данных в стиле карты, который реализует протоколы ``getitem()`` и ``len()`` и представляет карту от индексов/ключей до образцов данных. Он также работает с повторяющимися наборами данных с аргументом случайного выбора ``False``.\n",
    "\n",
    "\n",
    "Перед отправкой в модель функция ``collate_fn`` работает с пакетом образцов, сгенерированных из ``DataLoader``. Входом для ``collate_fn`` является пакет данных с размером пакета в ``DataLoader``, и ``collate_fn`` обрабатывает их в соответствии с конвейерами обработки данных, объявленными ранее. Обратите внимание на это и убедитесь, что ``collate_fn`` объявлен как def верхнего уровня. Это гарантирует, что функция доступна каждому исполнителю.\n",
    "\n",
    "В этом примере текстовые записи в исходном вводе пакета данных упаковываются в список и объединяются в один тензор для ввода ``nn.EmbeddingBag``. Смещение - это тензор разделителей, представляющий начальный индекс отдельной последовательности в текстовом тензоре. Метка - это тензор, сохраняющий метки отдельных текстовых записей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)    \n",
    "\n",
    "dataloader = DataLoader(train_data, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите модель\n",
    "----------------\n",
    "\n",
    "Модель состоит из `nn.EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>`__ слой плюс линейный слой для целей классификации. ``nn.EmbeddingBag`` с режимом по умолчанию «mean» вычисляет среднее значение «мешка» вложений. Хотя текстовые записи здесь имеют разную длину, модуль nn.EmbeddingBag здесь не требует заполнения, поскольку длина текста сохраняется в смещениях.\n",
    "\n",
    "Кроме того, поскольку ``nn.EmbeddingBag`` накапливает среднее значение по\n",
    "вложения на лету, ``nn.EmbeddingBag`` может улучшить\n",
    "производительность и эффективность памяти для обработки последовательности тензоров.\n",
    "\n",
    "![](../_static/img/text_sentiment_ngrams_model.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициировать экземпляр\n",
    "--------------------\n",
    "\n",
    "Набор данных ``AG_NEWS`` имеет четыре метки, поэтому количество классов равно четырем.\n",
    "\n",
    "::\n",
    "\n",
    "   1 : World мир\n",
    "   2 : Sports спорт\n",
    "   3 : Business Бизнес\n",
    "   4 : Sci/Tec Наука/Техника\n",
    "\n",
    "Мы строим модель с размером встраивания 64. Размер словаря равен длине экземпляра словаря. Количество классов равно количеству этикеток,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(cat_dict)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите функции для обучения модели и оценки результатов.\n",
    "---------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "#         print(sorted(label))\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите набор данных и запустите модель\n",
    "-----------------------------------\n",
    "\n",
    "Поскольку исходный ``AG_NEWS`` не имеет действительного набора данных, мы разделяем обучение\n",
    "набор данных в обучающие/действительные наборы с коэффициентом разделения 0,95 (train) и\n",
    "0,05 (valid). Здесь мы используем\n",
    "`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n",
    "в базовой библиотеке PyTorch.\n",
    "\n",
    "`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
    "критерий объединяет в одном классе ``nn.LogSoftmax()`` и ``nn.NLLLoss()``.\n",
    "Это полезно при обучении задаче классификации с помощью классов C.\n",
    "`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\n",
    "в качестве оптимизатора реализует метод стохастического градиентного спуска. Начальный\n",
    "скорость обучения установлена на 5.0.\n",
    "`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n",
    "здесь используется для регулировки скорости обучения по эпохам.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 2866 batches | accuracy    0.260\n",
      "| epoch   1 |  1000/ 2866 batches | accuracy    0.393\n",
      "| epoch   1 |  1500/ 2866 batches | accuracy    0.471\n",
      "| epoch   1 |  2000/ 2866 batches | accuracy    0.512\n",
      "| epoch   1 |  2500/ 2866 batches | accuracy    0.567\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.07s | valid accuracy    0.569 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 2866 batches | accuracy    0.612\n",
      "| epoch   2 |  1000/ 2866 batches | accuracy    0.634\n",
      "| epoch   2 |  1500/ 2866 batches | accuracy    0.641\n",
      "| epoch   2 |  2000/ 2866 batches | accuracy    0.646\n",
      "| epoch   2 |  2500/ 2866 batches | accuracy    0.663\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  5.94s | valid accuracy    0.651 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 2866 batches | accuracy    0.712\n",
      "| epoch   3 |  1000/ 2866 batches | accuracy    0.723\n",
      "| epoch   3 |  1500/ 2866 batches | accuracy    0.721\n",
      "| epoch   3 |  2000/ 2866 batches | accuracy    0.731\n",
      "| epoch   3 |  2500/ 2866 batches | accuracy    0.731\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.06s | valid accuracy    0.696 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 2866 batches | accuracy    0.776\n",
      "| epoch   4 |  1000/ 2866 batches | accuracy    0.775\n",
      "| epoch   4 |  1500/ 2866 batches | accuracy    0.784\n",
      "| epoch   4 |  2000/ 2866 batches | accuracy    0.786\n",
      "| epoch   4 |  2500/ 2866 batches | accuracy    0.784\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  6.09s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 2866 batches | accuracy    0.824\n",
      "| epoch   5 |  1000/ 2866 batches | accuracy    0.823\n",
      "| epoch   5 |  1500/ 2866 batches | accuracy    0.820\n",
      "| epoch   5 |  2000/ 2866 batches | accuracy    0.830\n",
      "| epoch   5 |  2500/ 2866 batches | accuracy    0.826\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  5.96s | valid accuracy    0.727 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 2866 batches | accuracy    0.864\n",
      "| epoch   6 |  1000/ 2866 batches | accuracy    0.857\n",
      "| epoch   6 |  1500/ 2866 batches | accuracy    0.854\n",
      "| epoch   6 |  2000/ 2866 batches | accuracy    0.859\n",
      "| epoch   6 |  2500/ 2866 batches | accuracy    0.862\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  5.98s | valid accuracy    0.745 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 2866 batches | accuracy    0.894\n",
      "| epoch   7 |  1000/ 2866 batches | accuracy    0.889\n",
      "| epoch   7 |  1500/ 2866 batches | accuracy    0.893\n",
      "| epoch   7 |  2000/ 2866 batches | accuracy    0.890\n",
      "| epoch   7 |  2500/ 2866 batches | accuracy    0.883\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  6.11s | valid accuracy    0.750 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 2866 batches | accuracy    0.916\n",
      "| epoch   8 |  1000/ 2866 batches | accuracy    0.916\n",
      "| epoch   8 |  1500/ 2866 batches | accuracy    0.915\n",
      "| epoch   8 |  2000/ 2866 batches | accuracy    0.904\n",
      "| epoch   8 |  2500/ 2866 batches | accuracy    0.914\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  6.12s | valid accuracy    0.753 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 2866 batches | accuracy    0.938\n",
      "| epoch   9 |  1000/ 2866 batches | accuracy    0.935\n",
      "| epoch   9 |  1500/ 2866 batches | accuracy    0.931\n",
      "| epoch   9 |  2000/ 2866 batches | accuracy    0.930\n",
      "| epoch   9 |  2500/ 2866 batches | accuracy    0.932\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  6.18s | valid accuracy    0.757 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 2866 batches | accuracy    0.950\n",
      "| epoch  10 |  1000/ 2866 batches | accuracy    0.952\n",
      "| epoch  10 |  1500/ 2866 batches | accuracy    0.946\n",
      "| epoch  10 |  2000/ 2866 batches | accuracy    0.945\n",
      "| epoch  10 |  2500/ 2866 batches | accuracy    0.946\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  6.06s | valid accuracy    0.758 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |   500/ 2866 batches | accuracy    0.965\n",
      "| epoch  11 |  1000/ 2866 batches | accuracy    0.958\n",
      "| epoch  11 |  1500/ 2866 batches | accuracy    0.958\n",
      "| epoch  11 |  2000/ 2866 batches | accuracy    0.956\n",
      "| epoch  11 |  2500/ 2866 batches | accuracy    0.960\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  6.24s | valid accuracy    0.760 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |   500/ 2866 batches | accuracy    0.970\n",
      "| epoch  12 |  1000/ 2866 batches | accuracy    0.968\n",
      "| epoch  12 |  1500/ 2866 batches | accuracy    0.968\n",
      "| epoch  12 |  2000/ 2866 batches | accuracy    0.971\n",
      "| epoch  12 |  2500/ 2866 batches | accuracy    0.965\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  6.41s | valid accuracy    0.763 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |   500/ 2866 batches | accuracy    0.976\n",
      "| epoch  13 |  1000/ 2866 batches | accuracy    0.977\n",
      "| epoch  13 |  1500/ 2866 batches | accuracy    0.974\n",
      "| epoch  13 |  2000/ 2866 batches | accuracy    0.975\n",
      "| epoch  13 |  2500/ 2866 batches | accuracy    0.975\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  6.28s | valid accuracy    0.766 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |   500/ 2866 batches | accuracy    0.983\n",
      "| epoch  14 |  1000/ 2866 batches | accuracy    0.981\n",
      "| epoch  14 |  1500/ 2866 batches | accuracy    0.978\n",
      "| epoch  14 |  2000/ 2866 batches | accuracy    0.977\n",
      "| epoch  14 |  2500/ 2866 batches | accuracy    0.978\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  6.23s | valid accuracy    0.767 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |   500/ 2866 batches | accuracy    0.987\n",
      "| epoch  15 |  1000/ 2866 batches | accuracy    0.981\n",
      "| epoch  15 |  1500/ 2866 batches | accuracy    0.981\n",
      "| epoch  15 |  2000/ 2866 batches | accuracy    0.983\n",
      "| epoch  15 |  2500/ 2866 batches | accuracy    0.981\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  6.33s | valid accuracy    0.763 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |   500/ 2866 batches | accuracy    0.989\n",
      "| epoch  16 |  1000/ 2866 batches | accuracy    0.988\n",
      "| epoch  16 |  1500/ 2866 batches | accuracy    0.990\n",
      "| epoch  16 |  2000/ 2866 batches | accuracy    0.989\n",
      "| epoch  16 |  2500/ 2866 batches | accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  6.27s | valid accuracy    0.767 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |   500/ 2866 batches | accuracy    0.990\n",
      "| epoch  17 |  1000/ 2866 batches | accuracy    0.990\n",
      "| epoch  17 |  1500/ 2866 batches | accuracy    0.991\n",
      "| epoch  17 |  2000/ 2866 batches | accuracy    0.990\n",
      "| epoch  17 |  2500/ 2866 batches | accuracy    0.988\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  6.05s | valid accuracy    0.770 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |   500/ 2866 batches | accuracy    0.990\n",
      "| epoch  18 |  1000/ 2866 batches | accuracy    0.990\n",
      "| epoch  18 |  1500/ 2866 batches | accuracy    0.991\n",
      "| epoch  18 |  2000/ 2866 batches | accuracy    0.991\n",
      "| epoch  18 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  6.62s | valid accuracy    0.770 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  19 |  1000/ 2866 batches | accuracy    0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  19 |  1500/ 2866 batches | accuracy    0.990\n",
      "| epoch  19 |  2000/ 2866 batches | accuracy    0.990\n",
      "| epoch  19 |  2500/ 2866 batches | accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time:  6.66s | valid accuracy    0.771 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |   500/ 2866 batches | accuracy    0.991\n",
      "| epoch  20 |  1000/ 2866 batches | accuracy    0.992\n",
      "| epoch  20 |  1500/ 2866 batches | accuracy    0.991\n",
      "| epoch  20 |  2000/ 2866 batches | accuracy    0.990\n",
      "| epoch  20 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time:  5.99s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  21 |   500/ 2866 batches | accuracy    0.990\n",
      "| epoch  21 |  1000/ 2866 batches | accuracy    0.991\n",
      "| epoch  21 |  1500/ 2866 batches | accuracy    0.993\n",
      "| epoch  21 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  21 |  2500/ 2866 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  21 | time:  6.41s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  22 |   500/ 2866 batches | accuracy    0.993\n",
      "| epoch  22 |  1000/ 2866 batches | accuracy    0.991\n",
      "| epoch  22 |  1500/ 2866 batches | accuracy    0.991\n",
      "| epoch  22 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  22 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  22 | time:  6.20s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  23 |   500/ 2866 batches | accuracy    0.993\n",
      "| epoch  23 |  1000/ 2866 batches | accuracy    0.992\n",
      "| epoch  23 |  1500/ 2866 batches | accuracy    0.993\n",
      "| epoch  23 |  2000/ 2866 batches | accuracy    0.991\n",
      "| epoch  23 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  23 | time:  6.23s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  24 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  24 |  1000/ 2866 batches | accuracy    0.991\n",
      "| epoch  24 |  1500/ 2866 batches | accuracy    0.992\n",
      "| epoch  24 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  24 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  24 | time:  6.17s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  25 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  25 |  1000/ 2866 batches | accuracy    0.991\n",
      "| epoch  25 |  1500/ 2866 batches | accuracy    0.993\n",
      "| epoch  25 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  25 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  25 | time:  6.33s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  26 |   500/ 2866 batches | accuracy    0.990\n",
      "| epoch  26 |  1000/ 2866 batches | accuracy    0.991\n",
      "| epoch  26 |  1500/ 2866 batches | accuracy    0.993\n",
      "| epoch  26 |  2000/ 2866 batches | accuracy    0.993\n",
      "| epoch  26 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  26 | time:  6.23s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  27 |   500/ 2866 batches | accuracy    0.993\n",
      "| epoch  27 |  1000/ 2866 batches | accuracy    0.993\n",
      "| epoch  27 |  1500/ 2866 batches | accuracy    0.992\n",
      "| epoch  27 |  2000/ 2866 batches | accuracy    0.991\n",
      "| epoch  27 |  2500/ 2866 batches | accuracy    0.990\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  27 | time:  6.35s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  28 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  28 |  1000/ 2866 batches | accuracy    0.992\n",
      "| epoch  28 |  1500/ 2866 batches | accuracy    0.991\n",
      "| epoch  28 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  28 |  2500/ 2866 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  28 | time:  6.37s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  29 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  29 |  1000/ 2866 batches | accuracy    0.992\n",
      "| epoch  29 |  1500/ 2866 batches | accuracy    0.990\n",
      "| epoch  29 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  29 |  2500/ 2866 batches | accuracy    0.992\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  29 | time:  6.27s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n",
      "| epoch  30 |   500/ 2866 batches | accuracy    0.992\n",
      "| epoch  30 |  1000/ 2866 batches | accuracy    0.993\n",
      "| epoch  30 |  1500/ 2866 batches | accuracy    0.990\n",
      "| epoch  30 |  2000/ 2866 batches | accuracy    0.992\n",
      "| epoch  30 |  2500/ 2866 batches | accuracy    0.991\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  30 | time:  6.22s | valid accuracy    0.769 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 45 # epoch\n",
    "LR = 4  # скорость обучения\n",
    "BATCH_SIZE = 16 # batch size for training\n",
    "  \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "# train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = list(train_data)\n",
    "test_dataset = list(test_data)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "# print(train_dataset)\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск модели на GPU со следующей распечаткой:\n",
    "\n",
    "::\n",
    "\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   1 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   2 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   3 | time:  0.03s | valid accuracy    0.450 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   4 | time:  0.03s | valid accuracy    0.650 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   5 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   6 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   7 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   8 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch   9 | time:  0.02s | valid accuracy    0.700 \n",
    "    -----------------------------------------------------------\n",
    "    -----------------------------------------------------------\n",
    "    | end of epoch  10 | time:  0.02s | valid accuracy    0.750 \n",
    "    -----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените модель с помощью тестового набора данных\n",
    "------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка результатов тестового набора данных…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка результатов тестового набора данных.\n",
      "точность теста    0.780\n"
     ]
    }
   ],
   "source": [
    "print('Проверка результатов тестового набора данных.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('точность теста {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::\n",
    "\n",
    "    Проверка результатов тестового набора данных.\n",
    "    точность теста    0.950\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест на случайной новости\n",
    "---------------------\n",
    "\n",
    "Используйте лучшую на данный момент модель и проверьте новости гольфа.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это 78 категория\n",
      "Примеры:\n",
      " ['Молоко 3,2%,шт' 'Молоко пастерилиз. т/рекс 2,5 %  1 л. 1/8 БМК'\n",
      " 'Сметана  Кубанский  Молочник  20%  180гр шт' 'СМЕТАНА 20% 300Г'\n",
      " 'Молоко Мудрая хозяйка 2,5% пленка 0,8 л БЗМЖ'\n",
      " '45Г ГЛ/СЫРКИ РОСТАГРО 20% ВН БЗМЖ' 'Пакет'\n",
      " 'Биойогурт \"Козимель\" натуральный,шт'\n",
      " 'Продукт кисломолочный Тема Биолакт 3,2% ТБА 208г'\n",
      " 'Йогурт питьевой Асеньевская фе' 'Сыр Российский 1кг 50% Россия БЗМЖ'\n",
      " 'Сметана 10г, 16 ккал' ' К.Ц.Яйца куриные стол.С2 10шт' 'ЯЙЦО ЭКСТРА С0'\n",
      " 'ЯЙЦО КУРИНОЕ С1 ВАРА' 'Йогурт фруктовый \"Вишня\" 2,5%,шт'\n",
      " 'Молоко Отборн Грин Агро 3,3-4,3% 1л пэт ГМЗ Артем'\n",
      " 'Молоко ФП пастериз т/топ 2,5 % 1,0л 1/6 Хладокомбинат'\n",
      " 'МАСЛО 82,5% ЭКОМ.' 'Яйцо кур С2 10шт пл/бл Племптицезавод'\n",
      " 'Мильфей с клубн.тартаром'\n",
      " 'БЗМЖ Сыр Сметанковый 45 - 50% 250г кусок Продукты из Елани'\n",
      " 'Сметана 20%,шт' 'ЯЙЦО СТОЛОВОЕ 1КАТ. ПТИЦЕФАБРИКА ПИОНЕРСКОЕ 10ШТ'\n",
      " 'Сыр с аром топл мол Черный принц 50% Беларусь'\n",
      " 'Коктейль детский молочный c шоколадом 2,5%,шт' 'МОЛОКО ПМЖЛ 2.5% 900Г'\n",
      " 'Мусс творожный с вишней,шт' 'Сметана 20'\n",
      " 'Яйцо кур С-1 10шт Все вкусное на стол Россия, шт'\n",
      " 'Сыр Мраморный 45% Беларусь' 'Сметана 100г, 159 ккал'\n",
      " 'Масло сливочн ДЕРЕВНЯ СЧАСТЛИВ' 'МОЛОКО ПАСТЕР 2,5%'\n",
      " 'Сыр Российский Село Зеленое 50% фас. 250 г БЗМЖ'\n",
      " 'Творог обезжиренный со сметаной,шт'\n",
      " 'Молоко коровье питьевое пастериз. 2,5% 1000гр Пюр-Пак'\n",
      " 'Кокт Молоч Речка Шоколад 2% БЗМЖ 0,2 МЛ' 'СЫРОК С ВАНИЛЬЮ'\n",
      " 'СЫРОК СУФЛ СОВ ТРАДИ'\n",
      " 'Йогурт десертный ФП земляника 2,5% 180г стакан 1/6'\n",
      " 'Сыр творожный \"Cremette\" 65%  800гр' 'М-З МОСК ПРОВ С ДОЗ'\n",
      " 'МОЛОКО 1Л УЛЬТРАПАСТ' 'Продукт кисломолочный Закваска 1,5% (буфет)'\n",
      " 'Творог 5% 280г шайба Серышевский'\n",
      " 'Кисл/мол продукт БиоМакс 450г 1,0% кефирный пл/б ВБД БЗМЖ'\n",
      " 'ЙогуртНежныйПерсикБЗМЖ5% 110г ван' 'СЫР МААСДАМ 45%'\n",
      " 'Молоко 0,95л 3,2% пл/б МолКом БЗМЖ']\n"
     ]
    }
   ],
   "source": [
    "cat_dict_inverted = dict(map(reversed, cat_dict.items()))\n",
    "\n",
    "def predict(text, text_pipeline = text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "ex_text_str = \"Сыр ПОШЕХОНСКИЙ 45% вес\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "predict_cat = predict(ex_text_str, text_pipeline)\n",
    "print(\"Это %s категория\" %cat_dict_inverted[predict_cat])\n",
    "exsempl_df = pd.DataFrame(train_data)\n",
    "print('Примеры:\\n', exsempl_df[exsempl_df[0] == predict_cat][1][:50].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18969645</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32644219</th>\n",
       "      <td>84</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37655096</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22391292</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25107157</th>\n",
       "      <td>84</td>\n",
       "      <td>ПАМПУШКА С ЧЕСНОК 30</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113565</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35855913</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36333025</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38930422</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23777916</th>\n",
       "      <td>203</td>\n",
       "      <td>Пакет</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          category_id             item_name  Pred\n",
       "18969645          203                 Пакет   164\n",
       "32644219           84                 Пакет   164\n",
       "37655096          203                 Пакет   164\n",
       "22391292          203                 Пакет   164\n",
       "25107157           84  ПАМПУШКА С ЧЕСНОК 30    71\n",
       "...               ...                   ...   ...\n",
       "5113565           203                 Пакет   164\n",
       "35855913          203                 Пакет   164\n",
       "36333025          203                 Пакет   164\n",
       "38930422          203                 Пакет   164\n",
       "23777916          203                 Пакет   164\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = pd.DataFrame({'item_name' : ['Лук', 'Хрен', 'Суп семи залуп', 'АИ95']})\n",
    "df_test = pd.read_pickle('../data/input/test_data_6350_rows.pkl')[['category_id', 'item_name']]\n",
    "df_test['Pred'] = df_test.item_name.apply(predict).map(dict(map(reversed, cat_dict.items())))\n",
    "df_test[df_test.category_id != df_test.Pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::\n",
    "\n",
    "       This is a Sports news\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
